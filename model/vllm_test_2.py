import base64
import time
import os
import random
import psutil
import pynvml
from openai import OpenAI
from concurrent.futures import ThreadPoolExecutor, as_completed
from statistics import median, quantiles

# ===================== å…¨å±€é…ç½®ï¼ˆæŒ‰éœ€ä¿®æ”¹ï¼‰ =====================
# VLLMæœåŠ¡é…ç½®
VLLM_BASE_URL = "http://10.136.234.255:8001/v1"
API_KEY = "dummy_key"
MODEL_PATH = "/workspace/work/zhipeng16/git/Multi_agent_image_tagging/model/Qwen/Qwen2.5-VL-3B-Instruct"

# æµ‹è¯•ç´ æé…ç½®ï¼ˆä»…3å¼ å›¾ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„ï¼‰
IMAGE_FOLDER = "/workspace/work/zhipeng16/git/Multi_agent_image_tagging/æ— ä»–å›¾ç‰‡æ ‡ç­¾æµ‹è¯•å›¾"  # æ›¿æ¢ä¸ºä½ çš„3å¼ å›¾ç‰‡æ‰€åœ¨æ–‡ä»¶å¤¹
PROMPT_TEMPLATES = [  # ä¸åŒçš„é—®é¢˜æ¨¡æ¿ï¼ˆéšæœºé€‰ï¼‰
    """
    ä»»åŠ¡ï¼šåˆ¤æ–­å›¾ç‰‡çš„æ ¸å¿ƒä¸»ä½“ï¼Œä»…ä»ä»¥ä¸‹ä¸€çº§åˆ†ç±»çš„å…­ä¸ªåˆ†ç±»ä¸­é€‰æ‹©1ä¸ªï¼ˆå¿…é¡»é€‰ï¼Œä¸æ–°å¢ï¼‰ï¼š
    ä¸€çº§åˆ†ç±»åˆ—è¡¨ï¼šäººåƒã€åŠ¨ç‰©ï¼ˆå® ç‰©ï¼‰ã€æ¤ç‰©ã€é£æ™¯ã€é£Ÿç‰©ã€å»ºç­‘
    å¦‚æœå›¾ç‰‡ä¸åœ¨è¿™ä¸ªå…­ä¸ªä¸»ä½“ä¸­ï¼Œè¯·é€‰æ‹©â€œå…¶ä»–â€ã€‚
    è¾“å‡ºè¦æ±‚ï¼šä»…è¿”å›åˆ†ç±»åç§°ï¼ˆå¦‚â€œäººåƒâ€â€œé£Ÿç‰©â€ï¼‰ï¼Œä¸æ·»åŠ ä»»ä½•é¢å¤–è§£é‡Šã€‚
    """,
    """
    ä»»åŠ¡ï¼šæè¿°å›¾ç‰‡çš„æ ¸å¿ƒåœºæ™¯ï¼Œä»…è¿”å›1ä¸ªå…³é”®è¯ï¼ˆå¦‚â€œå®¤å†…äººåƒâ€â€œæˆ·å¤–é£æ™¯â€â€œå® ç‰©ç‰¹å†™â€ï¼‰ï¼Œä¸æ·»åŠ é¢å¤–è§£é‡Šã€‚
    """,
    """
    ä»»åŠ¡ï¼šåˆ¤æ–­å›¾ç‰‡çš„ä¸»è‰²è°ƒï¼Œä»…ä»ä»¥ä¸‹é€‰é¡¹ä¸­é€‰1ä¸ªï¼šçº¢è‰²ã€è“è‰²ã€ç»¿è‰²ã€é»„è‰²ã€é»‘è‰²ã€ç™½è‰²ã€å½©è‰²ï¼Œä¸æ·»åŠ é¢å¤–è§£é‡Šã€‚
    """,
    """
    ä»»åŠ¡ï¼šåˆ¤æ–­å›¾ç‰‡æ˜¯å¦åŒ…å«äººç‰©ï¼Œä»…è¿”å›â€œæ˜¯â€æˆ–â€œå¦â€ï¼Œä¸æ·»åŠ ä»»ä½•é¢å¤–è§£é‡Šã€‚
    """,
    """
    ä»»åŠ¡ï¼šåˆ¤æ–­å›¾ç‰‡çš„æ‹æ‘„åœºæ™¯ï¼Œä»…ä»ä»¥ä¸‹é€‰é¡¹ä¸­é€‰1ä¸ªï¼šå®¤å†…ã€æˆ·å¤–ã€æ°´ä¸‹ã€ç©ºä¸­ï¼Œä¸æ·»åŠ é¢å¤–è§£é‡Šã€‚
    """
]

# å‹æµ‹é…ç½®ï¼ˆé€‚é…3å¼ å›¾ç‰‡çš„æ¢¯åº¦å¹¶å‘æ•°ï¼Œé¿å…è¿‡åº¦å¤ç”¨ï¼‰
CONCURRENT_NUM_LIST = [50, 60, 100, 150, 200]  # æœ€é«˜20å¹¶å‘ï¼ˆ3å¼ å›¾å„å¤ç”¨6-7æ¬¡ï¼‰
MAX_WORKERS = 200  # çº¿ç¨‹æ± æœ€å¤§çº¿ç¨‹æ•°ï¼ˆâ‰¥æœ€å¤§å¹¶å‘æ•°ï¼‰
REQUEST_TIMEOUT = 30  # å•è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

# ===================== å·¥å…·å‡½æ•° =====================
# åˆå§‹åŒ–GPUç›‘æ§ï¼ˆpynvmlï¼‰
def init_gpu_monitor():
    try:
        pynvml.nvmlInit()
        return pynvml
    except Exception as e:
        print(f"GPUç›‘æ§åˆå§‹åŒ–å¤±è´¥ï¼š{e}ï¼Œå°†è·³è¿‡GPUçŠ¶æ€æ‰“å°")
        return None

# è·å–GPUå®æ—¶çŠ¶æ€ï¼ˆæ˜¾å­˜/åˆ©ç”¨ç‡ï¼‰
def get_gpu_status(nvml):
    if not nvml:
        return "GPUç›‘æ§æœªå¯ç”¨"
    status = []
    device_count = nvml.nvmlDeviceGetCount()
    for i in range(device_count):
        handle = nvml.nvmlDeviceGetHandleByIndex(i)
        mem_info = nvml.nvmlDeviceGetMemoryInfo(handle)
        util = nvml.nvmlDeviceGetUtilizationRates(handle)
        status.append(
            f"GPU{i}: æ˜¾å­˜å ç”¨ {mem_info.used/1024/1024/1024:.1f}GB/{mem_info.total/1024/1024/1024:.1f}GB, åˆ©ç”¨ç‡ {util.gpu}%"
        )
    return "\n".join(status)

# å›¾ç‰‡è½¬base64
def image_to_base64(image_path):
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")

# è·å–æ–‡ä»¶å¤¹å†…æ‰€æœ‰æœ‰æ•ˆå›¾ç‰‡è·¯å¾„
def get_all_image_paths(folder):
    image_ext = [".jpg", ".jpeg", ".png", ".bmp"]
    paths = []

    # image_paths = []
    for root, _, files in os.walk(folder):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                paths.append(os.path.join(root, file))
    # for file in os.listdir(folder):
    #     file_path = os.path.join(folder, file)
    #     if os.path.isfile(file_path) and os.path.splitext(file)[1].lower() in image_ext:
    #         paths.append(file_path)
    if not paths:
        raise ValueError(f"å›¾ç‰‡æ–‡ä»¶å¤¹{folder}ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆå›¾ç‰‡")
    print(f"æ£€æµ‹åˆ°æµ‹è¯•å›¾ç‰‡ï¼š{[os.path.basename(p) for p in paths]}ï¼ˆå…±{len(paths)}å¼ ï¼‰ï¼Œå°†å¾ªç¯å¤ç”¨")
    return paths

# å•è¯·æ±‚å‡½æ•°ï¼ˆéšæœºé€‰é—®é¢˜+å¾ªç¯å¤ç”¨å›¾ç‰‡ï¼‰
def send_request(request_id, client, image_path, prompt_templates):
    start_time = time.time()
    # éšæœºé€‰ä¸€ä¸ªé—®é¢˜æ¨¡æ¿
    prompt = random.choice(prompt_templates)
    try:
        # åŠ è½½å›¾ç‰‡ï¼ˆæ¯ä¸ªè¯·æ±‚ç‹¬ç«‹åŠ è½½ï¼Œå¤ç”¨å›¾ç‰‡è·¯å¾„ï¼‰
        image_base64 = image_to_base64(image_path)
        # å‘é€è¯·æ±‚
        completion = client.chat.completions.create(
            model=MODEL_PATH,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
                    ]
                }
            ],
            temperature=0.7,
            max_tokens=1024,
            timeout=REQUEST_TIMEOUT
        )
        cost_time = time.time() - start_time
        return {
            "request_id": request_id,
            "image_path": os.path.basename(image_path),
            "prompt": prompt.strip()[:50] + "..." if len(prompt.strip())>50 else prompt.strip(),
            "cost_time": cost_time,
            "success": True,
            "result": completion.choices[0].message.content.strip(),
            "error": None
        }
    except Exception as e:
        cost_time = time.time() - start_time
        return {
            "request_id": request_id,
            "image_path": os.path.basename(image_path),
            "prompt": prompt.strip()[:50] + "..." if len(prompt.strip())>50 else prompt.strip(),
            "cost_time": cost_time,
            "success": False,
            "result": None,
            "error": str(e)[:100] + "..." if len(str(e))>100 else str(e)
        }

# ç»Ÿè®¡å‹æµ‹ç»“æœï¼ˆå«95åˆ†ä½å“åº”æ—¶é—´ï¼‰
def stat_results(results, total_time, concurrent_num):
    success_num = sum(1 for r in results if r["success"])
    fail_num = concurrent_num - success_num
    success_rate = success_num / concurrent_num * 100 if concurrent_num > 0 else 0
    qps = concurrent_num / total_time if total_time > 0 else 0
    
    # å“åº”æ—¶é—´ç»Ÿè®¡
    cost_times = [r["cost_time"] for r in results if r["success"]]
    avg_cost = sum(cost_times) / len(cost_times) if cost_times else 0
    p95_cost = quantiles(cost_times, n=20)[18] if len(cost_times)>=20 else (max(cost_times) if cost_times else 0)
    median_cost = median(cost_times) if cost_times else 0

    return {
        "concurrent_num": concurrent_num,
        "total_time": total_time,
        "success_num": success_num,
        "fail_num": fail_num,
        "success_rate": success_rate,
        "qps": qps,
        "avg_cost": avg_cost,
        "median_cost": median_cost,
        "p95_cost": p95_cost
    }

if __name__ == "__main__":
    # 1. åˆå§‹åŒ–èµ„æº
    nvml = init_gpu_monitor()
    client = OpenAI(base_url=VLLM_BASE_URL, api_key=API_KEY)
    all_image_paths = get_all_image_paths(IMAGE_FOLDER)
    final_report = []  # å­˜å‚¨æ‰€æœ‰å¹¶å‘æ•°çš„æµ‹è¯•ç»“æœ

    print("\n===== VLLMå¹¶å‘æµ‹è¯•ï¼ˆéšæœºå›¾ç‰‡+ä¸åŒé—®é¢˜ï¼‰=====")
    print(f"æ€»å›¾ç‰‡æ•°é‡ï¼š{len(all_image_paths)}å¼ ")
    print(f"é—®é¢˜æ¨¡æ¿æ•°é‡ï¼š{len(PROMPT_TEMPLATES)}ä¸ª")
    print(f"æ¢¯åº¦å¹¶å‘æ•°ï¼š{CONCURRENT_NUM_LIST}")
    print("="*50 + "\n")

    # 2. æ¢¯åº¦å‹æµ‹ï¼ˆé€ä¸ªå¹¶å‘æ•°æµ‹è¯•ï¼‰
    for concurrent_num in CONCURRENT_NUM_LIST:
        # ä¿®æ”¹ç‚¹1ï¼šéšæœºæŠ½å–å›¾ç‰‡ï¼Œå¢åŠ å¤šæ ·æ€§
        import random
        
        if concurrent_num <= len(all_image_paths):
            # å¦‚æœå¹¶å‘æ•°å°äºç­‰äºå›¾ç‰‡æ€»æ•°ï¼Œéšæœºé€‰æ‹©ä¸é‡å¤çš„å›¾ç‰‡
            test_image_paths = random.sample(all_image_paths, concurrent_num)
        else:
            # å¦‚æœå¹¶å‘æ•°å¤§äºå›¾ç‰‡æ€»æ•°ï¼Œå…ˆéšæœºé€‰æ‹©æ‰€æœ‰å›¾ç‰‡ï¼Œå†è¡¥å……éšæœºå›¾ç‰‡
            test_image_paths = random.sample(all_image_paths, len(all_image_paths))
            # è¡¥å……å‰©ä½™æ•°é‡ï¼ˆå…è®¸é‡å¤ï¼Œä½†å°½é‡é™ä½é‡å¤ç‡ï¼‰
            remaining = concurrent_num - len(all_image_paths)
            for i in range(remaining):
                # éšæœºé€‰æ‹©å›¾ç‰‡ï¼Œå¯ä»¥é‡å¤ä½†æ‰“ä¹±é¡ºåº
                test_image_paths.append(random.choice(all_image_paths))
            # æ‰“ä¹±é¡ºåºï¼Œé¿å…ç›¸åŒå›¾ç‰‡è¿ç»­å‡ºç°
            random.shuffle(test_image_paths)
        
        # ä¿®æ”¹ç‚¹2ï¼šç»Ÿè®¡å›¾ç‰‡ä½¿ç”¨æƒ…å†µ
        image_usage = {}
        for img_path in test_image_paths:
            img_name = os.path.basename(img_path)
            image_usage[img_name] = image_usage.get(img_name, 0) + 1
        
        # æ‰¾å‡ºæœ€å¸¸ç”¨å’Œæœ€ä¸å¸¸ç”¨çš„å›¾ç‰‡
        if image_usage:
            most_used = max(image_usage.items(), key=lambda x: x[1])
            least_used = min(image_usage.items(), key=lambda x: x[1])
            unique_images = len(image_usage)
        else:
            most_used = ("None", 0)
            least_used = ("None", 0)
            unique_images = 0
        
        print(f"å¼€å§‹æµ‹è¯•å¹¶å‘æ•°ï¼š{concurrent_num}")
        print(f"å›¾ç‰‡åˆ†é…ï¼šä½¿ç”¨{unique_images}å¼ ä¸åŒå›¾ç‰‡ï¼ˆå…±{len(all_image_paths)}å¼ ï¼‰")
        print(f"å›¾ç‰‡å¤ç”¨æƒ…å†µï¼šæœ€å¸¸ç”¨å›¾ç‰‡'{most_used[0]}'ä½¿ç”¨{most_used[1]}æ¬¡ï¼Œæœ€å°‘ç”¨å›¾ç‰‡'{least_used[0]}'ä½¿ç”¨{least_used[1]}æ¬¡")
        print(f"å½“å‰GPUçŠ¶æ€ï¼š\n{get_gpu_status(nvml)}")
        
        # ä¿®æ”¹ç‚¹3ï¼šæ˜¾ç¤ºå‰10ä¸ªè¯·æ±‚çš„å›¾ç‰‡åˆ†é…ï¼ˆæŠ½æ ·æŸ¥çœ‹ï¼‰
        if concurrent_num <= 50:
            sample_size = min(10, concurrent_num)
            sample_images = [os.path.basename(test_image_paths[i]) for i in range(sample_size)]
            print(f"å‰{sample_size}ä¸ªè¯·æ±‚å›¾ç‰‡æ ·æœ¬ï¼š{sample_images}")
        else:
            # æŠ½æ ·æ˜¾ç¤º
            sample_indices = random.sample(range(concurrent_num), min(10, concurrent_num))
            sample_images = [os.path.basename(test_image_paths[i]) for i in sample_indices]
            print(f"éšæœºæŠ½æ ·10ä¸ªè¯·æ±‚å›¾ç‰‡ï¼š{sample_images}")
        
        # æ‰§è¡Œå¹¶å‘è¯·æ±‚
        start_total_time = time.time()
        results = []
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            futures = [
                executor.submit(send_request, i, client, test_image_paths[i], PROMPT_TEMPLATES)
                for i in range(concurrent_num)
            ]
            for future in as_completed(futures):
                results.append(future.result())
        
        # ç»Ÿè®¡ç»“æœ
        total_time = time.time() - start_total_time
        stat = stat_results(results, total_time, concurrent_num)
        final_report.append(stat)

        # ä¿®æ”¹ç‚¹4ï¼šæ·»åŠ å›¾ç‰‡å¤šæ ·æ€§æŒ‡æ ‡åˆ°ç»Ÿè®¡ç»“æœ
        stat["unique_images"] = unique_images
        stat["max_image_reuse"] = most_used[1]
        
        # æ‰“å°å½“å‰å¹¶å‘æ•°çš„ç»“æœ
        print(f"\n===== å¹¶å‘æ•°{concurrent_num}æµ‹è¯•ç»“æœ =====")
        print(f"æ€»è€—æ—¶ï¼š{total_time:.2f} ç§’")
        print(f"æˆåŠŸæ•°ï¼š{stat['success_num']} | å¤±è´¥æ•°ï¼š{stat['fail_num']} | æˆåŠŸç‡ï¼š{stat['success_rate']:.2f}%")
        print(f"QPSï¼ˆæ¯ç§’å¤„ç†è¯·æ±‚æ•°ï¼‰ï¼š{stat['qps']:.2f}")
        print(f"å¹³å‡å“åº”æ—¶é—´ï¼š{stat['avg_cost']:.2f} ç§’")
        print(f"ä¸­ä½æ•°å“åº”æ—¶é—´ï¼š{stat['median_cost']:.2f} ç§’")
        print(f"95åˆ†ä½å“åº”æ—¶é—´ï¼š{stat['p95_cost']:.2f} ç§’")
        print(f"å›¾ç‰‡å¤šæ ·æ€§ï¼šä½¿ç”¨{unique_images}å¼ ä¸åŒå›¾ç‰‡ï¼Œæœ€å¤§å¤ç”¨{most_used[1]}æ¬¡")
        print(f"æµ‹è¯•åGPUçŠ¶æ€ï¼š\n{get_gpu_status(nvml)}")

        # æ‰“å°å¤±è´¥è¯·æ±‚è¯¦æƒ…ï¼ˆå¦‚æœ‰ï¼‰
        if stat["fail_num"] > 0:
            print("\nâš ï¸ å¤±è´¥è¯·æ±‚è¯¦æƒ…ï¼š")
            fail_results = [r for r in results if not r["success"]]
            for r in fail_results[:5]:  # ä»…æ‰“å°å‰5æ¡
                print(f"è¯·æ±‚ID{r['request_id']} | å›¾ç‰‡{r['image_path']} | é”™è¯¯ï¼š{r['error']}")
        
        # ä¿®æ”¹ç‚¹5ï¼šæ˜¾ç¤ºä¸€äº›æˆåŠŸè¯·æ±‚çš„ç»“æœç¤ºä¾‹
        if stat["success_num"] > 0:
            print("\nâœ… æˆåŠŸè¯·æ±‚ç¤ºä¾‹ï¼ˆå‰3ä¸ªï¼‰ï¼š")
            success_results = [r for r in results if r["success"]]
            for i, r in enumerate(success_results[:3]):
                print(f"  è¯·æ±‚{r['request_id']}: å›¾ç‰‡'{r['image_path']}' -> å›ç­”: {r['result'][:50]}...")
        
        print("="*50 + "\n")
        time.sleep(2)  # æµ‹è¯•é—´éš”ï¼Œè®©GPUç¨ä½œä¼‘æ¯

    # 3. æ‰“å°æœ€ç»ˆæ±‡æ€»æŠ¥å‘Šï¼ˆå¢åŠ å›¾ç‰‡å¤šæ ·æ€§åˆ—ï¼‰
    print("===== æœ€ç»ˆæ±‡æ€»æŠ¥å‘Šï¼ˆæ‰€æœ‰å¹¶å‘æ•°ï¼‰=====")
    print(f"{'å¹¶å‘æ•°':<6} {'æˆåŠŸç‡(%)':<10} {'QPS':<8} {'å¹³å‡å“åº”æ—¶é—´(s)':<15} {'95åˆ†ä½å“åº”æ—¶é—´(s)':<18} {'å”¯ä¸€å›¾ç‰‡æ•°':<12} {'æœ€å¤§å¤ç”¨':<10}")
    print("-"*85)
    for stat in final_report:
        print(
            f"{stat['concurrent_num']:<6} "
            f"{stat['success_rate']:<10.2f} "
            f"{stat['qps']:<8.2f} "
            f"{stat['avg_cost']:<15.2f} "
            f"{stat['p95_cost']:<18.2f} "
            f"{stat.get('unique_images', 0):<12} "
            f"{stat.get('max_image_reuse', 0):<10}"
        )

    # 4. è¾“å‡ºæé™å¹¶å‘æ•°ï¼ˆæˆåŠŸç‡â‰¥95%çš„æœ€å¤§å¹¶å‘æ•°ï¼‰
    valid_stats = [s for s in final_report if s["success_rate"] >= 95]
    if valid_stats:
        max_valid_concurrent = max(valid_stats, key=lambda x: x["concurrent_num"])
        print(f"\nâœ… æé™å¹¶å‘æ•°ï¼ˆæˆåŠŸç‡â‰¥95%ï¼‰ï¼š{max_valid_concurrent['concurrent_num']}")
        print(f"è¯¥å¹¶å‘æ•°ä¸‹QPSï¼š{max_valid_concurrent['qps']:.2f}")
        print(f"95åˆ†ä½å“åº”æ—¶é—´ï¼š{max_valid_concurrent['p95_cost']:.2f}ç§’")
        print(f"å›¾ç‰‡å¤šæ ·æ€§ï¼š{max_valid_concurrent.get('unique_images', 0)}å¼ ä¸åŒå›¾ç‰‡")
    else:
        print("\nâŒ æ‰€æœ‰æµ‹è¯•å¹¶å‘æ•°çš„æˆåŠŸç‡å‡<95%ï¼Œè¯·æ£€æŸ¥VLLMé…ç½®æˆ–é™ä½å¹¶å‘æ•°")
    
    # 5. åˆ†ææ€§èƒ½è¶‹åŠ¿
    print("\n===== æ€§èƒ½è¶‹åŠ¿åˆ†æ =====")
    if len(final_report) >= 2:
        first_stat = final_report[0]
        last_stat = final_report[-1]
        
        qps_growth = (last_stat['qps'] / first_stat['qps'] - 1) * 100 if first_stat['qps'] > 0 else 0
        avg_latency_growth = (last_stat['avg_cost'] / first_stat['avg_cost'] - 1) * 100 if first_stat['avg_cost'] > 0 else 0
        
        print(f"ä»{first_stat['concurrent_num']}åˆ°{last_stat['concurrent_num']}å¹¶å‘ï¼š")
        print(f"  QPSå˜åŒ–ï¼š{first_stat['qps']:.2f} â†’ {last_stat['qps']:.2f} ({qps_growth:+.1f}%)")
        print(f"  å¹³å‡å»¶è¿Ÿå˜åŒ–ï¼š{first_stat['avg_cost']:.2f}s â†’ {last_stat['avg_cost']:.2f}s ({avg_latency_growth:+.1f}%)")
        
        if qps_growth < 20 and last_stat['concurrent_num'] > first_stat['concurrent_num'] * 2:
            print("  âš ï¸ è­¦å‘Šï¼šå¹¶å‘æ•°ç¿»å€ä½†QPSå¢é•¿ä¸è¶³20%ï¼Œå¯èƒ½å­˜åœ¨æ€§èƒ½ç“¶é¢ˆ")
        
        # æ‰¾åˆ°QPSå¼€å§‹ä¸‹é™çš„è½¬æŠ˜ç‚¹
        max_qps_stat = max(final_report, key=lambda x: x['qps'])
        if max_qps_stat['concurrent_num'] < last_stat['concurrent_num']:
            print(f"  ğŸ“‰ QPSåœ¨{max_qps_stat['concurrent_num']}å¹¶å‘æ—¶è¾¾åˆ°å³°å€¼{max_qps_stat['qps']:.2f}ï¼Œä¹‹åå¼€å§‹ä¸‹é™")

    # æ¸…ç†GPUç›‘æ§èµ„æº
    if nvml:
        nvml.nvmlShutdown()

# # ===================== ä¸»å‹æµ‹æµç¨‹ï¼ˆæ ¸å¿ƒï¼šå¾ªç¯å¤ç”¨å›¾ç‰‡ï¼‰ =====================
# if __name__ == "__main__":
#     # 1. åˆå§‹åŒ–èµ„æº
#     nvml = init_gpu_monitor()
#     client = OpenAI(base_url=VLLM_BASE_URL, api_key=API_KEY)
#     all_image_paths = get_all_image_paths(IMAGE_FOLDER)
#     final_report = []  # å­˜å‚¨æ‰€æœ‰å¹¶å‘æ•°çš„æµ‹è¯•ç»“æœ

#     print("\n===== VLLMå¹¶å‘æµ‹è¯•=====")
#     print(f"æµ‹è¯•å›¾ç‰‡æ•°é‡ï¼š{len(all_image_paths)}")
#     print(f"é—®é¢˜æ¨¡æ¿æ•°é‡ï¼š{len(PROMPT_TEMPLATES)}")
#     print(f"æ¢¯åº¦å¹¶å‘æ•°ï¼š{CONCURRENT_NUM_LIST}")
#     print("="*50 + "\n")

#     # 2. æ¢¯åº¦å‹æµ‹ï¼ˆé€ä¸ªå¹¶å‘æ•°æµ‹è¯•ï¼‰
#     for concurrent_num in CONCURRENT_NUM_LIST:
#         # æ ¸å¿ƒä¿®æ”¹ï¼šå¾ªç¯å¤ç”¨å›¾ç‰‡ï¼ˆå–æ¨¡å®ç°ï¼‰
#         test_image_paths = []
#         for i in range(concurrent_num):
#             test_image_paths.append(all_image_paths[i % len(all_image_paths)])
        
#         print(f"å¼€å§‹æµ‹è¯•å¹¶å‘æ•°ï¼š{concurrent_num}")
#         print(f"æœ¬æ¬¡æµ‹è¯•å›¾ç‰‡åˆ†é…ï¼ˆå¾ªç¯å¤ç”¨ï¼‰ï¼š{[os.path.basename(p) for p in test_image_paths]}")
#         print(f"å½“å‰GPUçŠ¶æ€ï¼š\n{get_gpu_status(nvml)}")
        
#         # æ‰§è¡Œå¹¶å‘è¯·æ±‚
#         start_total_time = time.time()
#         results = []
#         with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
#             futures = [
#                 executor.submit(send_request, i, client, test_image_paths[i], PROMPT_TEMPLATES)
#                 for i in range(concurrent_num)
#             ]
#             for future in as_completed(futures):
#                 results.append(future.result())
        
#         # ç»Ÿè®¡ç»“æœ
#         total_time = time.time() - start_total_time
#         stat = stat_results(results, total_time, concurrent_num)
#         final_report.append(stat)

#         # æ‰“å°å½“å‰å¹¶å‘æ•°çš„ç»“æœ
#         print(f"\n===== å¹¶å‘æ•°{concurrent_num}æµ‹è¯•ç»“æœ =====")
#         print(f"æ€»è€—æ—¶ï¼š{total_time:.2f} ç§’")
#         print(f"æˆåŠŸæ•°ï¼š{stat['success_num']} | å¤±è´¥æ•°ï¼š{stat['fail_num']} | æˆåŠŸç‡ï¼š{stat['success_rate']:.2f}%")
#         print(f"QPSï¼ˆæ¯ç§’å¤„ç†è¯·æ±‚æ•°ï¼‰ï¼š{stat['qps']:.2f}")
#         print(f"å¹³å‡å“åº”æ—¶é—´ï¼š{stat['avg_cost']:.2f} ç§’")
#         print(f"ä¸­ä½æ•°å“åº”æ—¶é—´ï¼š{stat['median_cost']:.2f} ç§’")
#         print(f"95åˆ†ä½å“åº”æ—¶é—´ï¼š{stat['p95_cost']:.2f} ç§’")
#         print(f"æµ‹è¯•åGPUçŠ¶æ€ï¼š\n{get_gpu_status(nvml)}")

#         # æ‰“å°å¤±è´¥è¯·æ±‚è¯¦æƒ…ï¼ˆå¦‚æœ‰ï¼‰
#         if stat["fail_num"] > 0:
#             print("\nâš ï¸ å¤±è´¥è¯·æ±‚è¯¦æƒ…ï¼š")
#             fail_results = [r for r in results if not r["success"]]
#             for r in fail_results[:5]:  # ä»…æ‰“å°å‰5æ¡
#                 print(f"è¯·æ±‚ID{r['request_id']} | å›¾ç‰‡{r['image_path']} | é”™è¯¯ï¼š{r['error']}")
#         print("="*50 + "\n")
#         time.sleep(2)  # æµ‹è¯•é—´éš”ï¼Œè®©GPUç¨ä½œä¼‘æ¯

#     # 3. æ‰“å°æœ€ç»ˆæ±‡æ€»æŠ¥å‘Š
#     print("===== æœ€ç»ˆæ±‡æ€»æŠ¥å‘Šï¼ˆæ‰€æœ‰å¹¶å‘æ•°ï¼‰=====")
#     print(f"{'å¹¶å‘æ•°':<6} {'æˆåŠŸç‡(%)':<10} {'QPS':<8} {'å¹³å‡å“åº”æ—¶é—´(s)':<15} {'95åˆ†ä½å“åº”æ—¶é—´(s)':<18}")
#     print("-"*60)
#     for stat in final_report:
#         print(
#             f"{stat['concurrent_num']:<6} "
#             f"{stat['success_rate']:<10.2f} "
#             f"{stat['qps']:<8.2f} "
#             f"{stat['avg_cost']:<15.2f} "
#             f"{stat['p95_cost']:<18.2f}"
#         )

#     # 4. è¾“å‡ºæé™å¹¶å‘æ•°ï¼ˆæˆåŠŸç‡â‰¥95%çš„æœ€å¤§å¹¶å‘æ•°ï¼‰
#     valid_stats = [s for s in final_report if s["success_rate"] >= 95]
#     if valid_stats:
#         max_valid_concurrent = max(valid_stats, key=lambda x: x["concurrent_num"])
#         print(f"\nâœ… æé™å¹¶å‘æ•°ï¼ˆæˆåŠŸç‡â‰¥95%ï¼‰ï¼š{max_valid_concurrent['concurrent_num']}")
#         print(f"è¯¥å¹¶å‘æ•°ä¸‹QPSï¼š{max_valid_concurrent['qps']:.2f}ï¼Œ95åˆ†ä½å“åº”æ—¶é—´ï¼š{max_valid_concurrent['p95_cost']:.2f}ç§’")
#     else:
#         print("\nâŒ æ‰€æœ‰æµ‹è¯•å¹¶å‘æ•°çš„æˆåŠŸç‡å‡<95%ï¼Œè¯·æ£€æŸ¥VLLMé…ç½®æˆ–é™ä½å¹¶å‘æ•°")

#     # æ¸…ç†GPUç›‘æ§èµ„æº
#     if nvml:
#         nvml.nvmlShutdown()